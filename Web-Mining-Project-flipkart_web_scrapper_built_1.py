# -*- coding: utf-8 -*-
"""FlipKart Web Scrapper Built-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6eQZLWQ6YNmm7LjbrdgQhXIoAbcklzg

#**Web Scraping with Analysis in Python**
---
"""

pip install fake-useragent --quiet

import requests
from fake_useragent import UserAgent
import pandas as pd
import bs4
import matplotlib.pyplot as plt
import seaborn as sns

# Give the input of the product you are looking for along with the Budget range

product_name = input("Enter the name of the product you're searching for: ")
print("Enter your budget range ")
start_price = int(input("   Start Range (₹): " ))
end_price = int(input("    End Range (₹): " ))

"""We create lists for storing the product and it's featres along with the dataframe to store the entire data extracted from the unstructured format to structued format"""

product = []
rating = []
price = []

df = pd.DataFrame()

"""### Creating the user agent"""

user_agent = UserAgent()

"""### Extracting data from multiple pages of the product listing, we're going to use a for loop.

The range will specify the number 0f pages to be extracted

The data that we extract is unstructed data, so we'll create empty lists to store them in a structured form

---

Crawling and scraping the data from the website. Once extracted entire data from the web site, store it in  the data frame :
"""

for i in range (1,10) :
  url = "https://www.flipkart.com/search?q={0}&page={1}"
  url = url.format(product_name,i)
  print("URL : ",url)

  # Getting the response from the page using get method of requests module
  page = requests.get(url, headers={"User-agent" : user_agent.chrome})

  # Storing the content of the page in a variable
  html = page.content

  # Creating BeautifulSoup object
  page_soup = bs4.BeautifulSoup(html,"html.parser")

  for containers in page_soup.findAll('div',{'class':'_2kHMtA'}) :
    name = containers.find('div', attrs={'class':'_4rR01T'})
    product.append(name.text)

    rate = containers.find('div',attrs={'class':'_3LWZlK'})
    rating.append(rate.text) if type(rate) == bs4.element.Tag else rating.append('NaN')

    cost = containers.find('div',attrs={'class':'_30jeq3 _1_WHN1'})
    price.append(cost.text) if type(cost) == bs4.element.Tag else price.append('NaN')

df = pd.DataFrame({'Product Name':product, 'Rating':rating, 'Price':price})

#just checking out the DataFrame
df

df.shape

"""### Data Cleaning for our analysis

---

Triming the curreny "₹" and "," and have only the numeric price in the column.

We use Regex to convert the datatype of the price column to String as the datatype of all the columns is object by default

Once it is trmmed, covert teh datatype of Price and Rating to float type
"""

df['Price'] = df['Price'].str.lstrip('₹')
df["Price"] = df['Price'].replace({',':''}, regex=True)

# Converting the datatypes of the columns from object to Float
df['Price'] = df['Price'].astype(float)
df['Rating'] = df['Rating'].astype(float)

df.dtypes

"""### Removing the duplicates in the data"""

df.drop_duplicates(subset="Product Name", keep=False, inplace=True)   # inplace=True specifies that the df should be edited and a new one should not be made

"""### Data after trimming and conversions :"""

df.head()

print(df.shape)

"""### Filtering and sorting the price range which was inputed by user"""

df = df[(start_price < df['Price']) & (df['Price']< end_price)]
print(df.shape)
df1 = df.sort_values(['Price','Rating'], ascending = (False,False))
df1 = df.nlargest(25, ['Price','Rating'])                           # using the nlargest to select the top 25 rows of the rating and price (from the already sorted df)
df1

"""### Visualizing the Price data"""

#visualizing the items against price
fig, ax = plt.subplots()
ax.bar(df1['Product Name'],df1['Price'])
ax.set_xticklabels(df1['Product Name'], rotation = 90)
ax.set_ylabel("Price")
ax.set_xlabel("Product Name")
plt.show

"""Visualizing the Rating data"""

fig, ax = plt.subplots()
ax.bar(df['Product Name'], df1['Rating'])
ax.set_xticklabels(df1['Product Name'],rotation=90)
ax.set_ylabel("Rating")
ax.set_xlabel("Product Name")
plt.show()

"""Visualizing the Price VS Rating"""

sns.barplot(x=df1['Rating'], y=df1['Price'], linewidth=2.5)

"""### Savig the sorted data as a Excel file :"""

df.to_excel('mydata.xlsx', index=False)

"""### Making a Fucntion to periodically update all the data :"""

# def updateData(product_name,start_price,end_price) :
#   product = []
#   rating = []
#   price = []
#   df = pd.DataFrame()


#   for i in range (1,10) :
#     url = "https://www.flipkart.com/search?q={0}&page={1}"
#     url = url.format(product_name,i)
#     print("URL : ",url)

#     # Getting the response from the page using get method of requests module
#     page = requests.get(url, headers={"User-agent" : user_agent.chrome})

#     # Storing the content of the page in a variable
#     html = page.content

#     # Creating BeautifulSoup object
#     page_soup = bs4.BeautifulSoup(html,"html.parser")

#     for containers in page_soup.findAll('div',{'class':'_2kHMtA'}) :
#       name = containers.find('div', attrs={'class':'_4rR01T'})
#       product.append(name.text)

#       rate = containers.find('div',attrs={'class':'_3LWZlK'})
#       rating.append(rate.text) if type(rate) == bs4.element.Tag else rating.append('NaN')

#       cost = containers.find('div',attrs={'class':'_30jeq3 _1_WHN1'})
#       price.append(cost.text) if type(cost) == bs4.element.Tag else price.append('NaN')

#   # Making the dataframe
#   df=pd.DataFrame({'Product Name':product, 'Rating':rating, 'Price':price})

#   # Cleaning up the data :
#   df['Price'] = df['Price'].str.lstrip('₹')
#   df['Price'] = df['Price'].replace({',':''}, regex=True)

#   # Converting the datatypes of the columns from object to Float
#   df['Price'] = df['Price'].astype(float)
#   df['Rating'] = df['Rating'].astype(float)

#   # removing Dups :
#   df.drop_duplicates(subset="Product Name", keep=False, inplace=True)   # inplace=True specifies that the df should be edited and a new one should not be made

#   # Filtering and Sorting the Data for top products
#   df = df[(start_price < df['Price']) & (df['Price']< end_price)]
#   print(df.shape)
#   df1 = df.sort_values(['Price','Rating'], ascending = (False,False))
#   df1 = df.nlargest(25, ['Price','Rating'])

#   # Saving the new changes to the excel file :
#   df1.to_excel('myupdateddata.xlsx', index=False)

#   # return the updated dataframe
#   return df1

"""### Scheduling the Above fucntion to run at periodic intervals :"""

#!pip install schedule

# import time
# import schedule

# # Assigning the returned value to df variable
# df = updateData(product_name,start_price,end_price)

# # Scheduling the execution of updateData function every 10 seconds
# schedule.every(10).seconds.do(updateData,product_name,start_price,end_price)

# # Loop to keep the scheduler running
# while True:
#     schedule.run_pending()
#     time.sleep(1)

import time
import schedule

def updateData(product_name,start_price,end_price) :
  product = []
  rating = []
  price = []
  df = pd.DataFrame()


  for i in range (1,10) :
    url = "https://www.flipkart.com/search?q={0}&page={1}"
    url = url.format(product_name,i)
    print("URL : ",url)

    # Getting the response from the page using get method of requests module
    page = requests.get(url, headers={"User-agent" : user_agent.chrome})

    # Storing the content of the page in a variable
    html = page.content

    # Creating BeautifulSoup object
    page_soup = bs4.BeautifulSoup(html,"html.parser")

    for containers in page_soup.findAll('div',{'class':'_2kHMtA'}) :
      name = containers.find('div', attrs={'class':'_4rR01T'})
      product.append(name.text)

      rate = containers.find('div',attrs={'class':'_3LWZlK'})
      rating.append(rate.text) if type(rate) == bs4.element.Tag else rating.append('NaN')

      cost = containers.find('div',attrs={'class':'_30jeq3 _1_WHN1'})
      price.append(cost.text) if type(cost) == bs4.element.Tag else price.append('NaN')

  # Making the dataframe
  df=pd.DataFrame({'Product Name':product, 'Rating':rating, 'Price':price})
  print(df.head())

  # Cleaning up the data :
  df['Price'] = df['Price'].str.lstrip('₹')
  df['Price'] = df['Price'].replace({',':''}, regex=True)

  # Converting the datatypes of the columns from object to Float
  df['Price'] = df['Price'].astype(float)
  df['Rating'] = df['Rating'].astype(float)

  # removing Dups :
  df.drop_duplicates(subset="Product Name", keep=False, inplace=True)   # inplace=True specifies that the df should be edited and a new one should not be made

  # Filtering and Sorting the Data for top products
  df = df[(start_price < df['Price']) & (df['Price']< end_price)]
  print(df.shape)
  df1 = df.sort_values(['Price','Rating'], ascending = (False,False))
  df1 = df.nlargest(25, ['Price','Rating'])

  # Saving the new changes to the excel file :
  df.to_excel('myupdateddata.xlsx', index=False)

  return df   # return the updated dataframe

# Assigning the returned value to df variable
df = updateData(product_name,start_price,end_price)

# Scheduling the execution of updateData function every 10 seconds
schedule.every(10).seconds.do(updateData,product_name,start_price,end_price)

# Loop to keep the scheduler running
while True:
    schedule.run_pending()
    time.sleep(1)